\section{Conclusion}
\label{sec:conclusion}

In this paper, we presented a comparative analysis of extractive and abstractive summarization models on the BBC News dataset. Our results demonstrate that while abstractive models like BART offer superior fluency and higher ROUGE scores, extractive models like BERTSum remain valuable for their factual reliability and interpretability.

Future work could explore hybrid approaches that combine the strengths of both paradigms, such as using extractive models to select content for abstractive generators. Additionally, evaluating these models on low-resource languages or specialized domains would provide further insights into their robustness.
