\begin{abstract}
Text summarization is a fundamental challenge in Natural Language Processing, aiming to produce concise and coherent summaries of longer documents. In this paper, we present a comparative study of two leading approaches: extractive summarization using BERTSum and abstractive summarization using BART. We evaluate these models on the BBC News Summary dataset, analyzing their performance using standard ROUGE metrics and BERTScore. Our experiments reveal the trade-offs between the factual precision of extractive methods and the linguistic fluency of abstractive methods. We find that while BART generally achieves higher automated scores and better readability, BERTSum remains a competitive and efficient alternative for applications requiring strict adherence to source content.
\end{abstract}